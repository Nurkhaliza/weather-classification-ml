import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_curve, auc
from sklearn.preprocessing import label_binarize

# ====================== Konfigurasi Streamlit & Theme ======================
st.set_page_config(
    page_title="Klasifikasi Cuaca ML",
    page_icon="üå¶Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom Color Palette
RED_TO_GOLD = ["#EE8080", "#ED9080", "#EC9F80", "#EAB380", "#E8C680", "#E6D480"]
PRIMARY_COLOR = "#E07070"
SECONDARY_COLOR = "#EAB380"
ACCENT_COLOR = "#ED9080"

plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Judul Header
st.markdown(f"<h1 style='color:{PRIMARY_COLOR}; text-align:center;'>üå¶Ô∏è Klasifikasi Cuaca ML</h1>", unsafe_allow_html=True)

# Load Dataset
@st.cache_data
def load_data():
    df = pd.read_csv("weather_classification_data.csv")
    return df

# Preprocessing function (cached globally)
@st.cache_data
def preprocess_data():
    df = load_data()
    
    # Create encoders
    le_cloud = LabelEncoder()
    le_season = LabelEncoder()
    le_location = LabelEncoder()
    le_target = LabelEncoder()
    
    # Fit encoders on original data
    df_processed = df.copy()
    df_processed["Cloud Cover"] = le_cloud.fit_transform(df_processed["Cloud Cover"])
    df_processed["Season"] = le_season.fit_transform(df_processed["Season"])
    df_processed["Location"] = le_location.fit_transform(df_processed["Location"])
    
    # Scale features
    scaler = StandardScaler()
    numerical_cols = ["Temperature", "Humidity", "Wind Speed", "Precipitation (%)", 
                      "Atmospheric Pressure", "UV Index", "Visibility (km)"]
    df_processed[numerical_cols] = scaler.fit_transform(df_processed[numerical_cols])
    
    # Encode target
    y_encoded = le_target.fit_transform(df_processed["Weather Type"])
    X = df_processed.drop("Weather Type", axis=1)
    y = y_encoded
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    return {
        'df': df,
        'df_processed': df_processed,
        'X_train': X_train,
        'X_test': X_test,
        'y_train': y_train,
        'y_test': y_test,
        'le_cloud': le_cloud,
        'le_season': le_season,
        'le_location': le_location,
        'le_target': le_target,
        'scaler': scaler,
        'numerical_cols': numerical_cols,
        'X_columns': X.columns
    }

# Load preprocessed data
data = preprocess_data()
df = data['df']

# ====================== TAB NAVIGATION ======================
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(
    ["üìñ Tentang Dataset", "üìä Dashboard", "ü§ñ Machine Learning", "üèÜ Model Terbaik", "üéØ Prediksi", "üìß Hubungi Saya"]
)

# ====================== TAB 1: ABOUT DATASET ======================
with tab1:
    st.header("üìñ Tentang Dataset")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        **Sumber dan Deskripsi Dataset**
        
        Dataset cuaca ini adalah dataset sintetis yang dikumpulkan untuk mensimulasikan kondisi cuaca real-world dengan cara yang komprehensif. Dataset ini mencakup data dari berbagai lokasi geografis selama periode waktu yang signifikan, mencakup 1000 observasi dengan 11 variabel yang mencakup aspek meteorologi dan geografis. Data ini dirancang untuk memberikan representasi yang seimbang dari empat jenis cuaca utama: Rainy, Sunny, Cloudy, dan Snowy.
        """)
    
    with col2:
        st.metric("Total Rekam", len(df))
        st.metric("Total Fitur", len(df.columns))
    
    st.markdown("---")
    
    st.subheader("ÔøΩ Tujuan Analisis")
    
    st.markdown("""
    Penelitian ini bertujuan untuk mengembangkan dan membandingkan model-model machine learning yang dapat memprediksi jenis cuaca dengan akurat berdasarkan fitur-fitur meteorologi dan geografis yang tersedia. Dalam analisis ini, variabel respon (Y) yang digunakan adalah status cuaca (Weather Type) yang terdiri dari empat kategori: Rainy, Sunny, Cloudy, dan Snowy. Sementara itu, variabel-variabel prediktor meliputi suhu udara, kelembaban, kecepatan angin, tekanan atmosfer, indeks UV, jarak pandang, presipitasi, tutupan awan, musim, dan lokasi geografis.
    
    Variabel demografis dan lokasi dalam dataset meliputi lokasi pengambilan data (Urban, Coastal, Rural) serta musim (Winter, Spring, Summer, Fall) ketika data direkam. Variabel meteorologi utama mencakup suhu udara dalam satuan Celsius, kelembaban relatif dalam persen, dan kecepatan angin dalam kilometer per jam. Dataset juga mengandung fitur-fitur teknis seperti tekanan atmosfer (hPa), indeks ultraviolet (UV Index) 0-11, jarak pandang dalam kilometer, persentase presipitasi, dan deskripsi tutupan awan (Clear, Overcast, Partly Cloudy).
    
    Kami melakukan Exploratory Data Analysis (EDA) untuk memahami pola dan distribusi data, mengidentifikasi hubungan antar variabel, serta mendeteksi anomali atau outlier. Selanjutnya, kami mengembangkan lima algoritma machine learning yang berbeda - Logistic Regression, Random Forest, Gaussian Naive Bayes, Support Vector Machine, dan Gradient Boosting - untuk mengklasifikasikan jenis cuaca. Setiap algoritma dievaluasi menggunakan metrik Accuracy, Precision, Recall, dan F1-Score, serta visualisasi confusion matrix dan ROC curves untuk memberikan pemahaman mendalam tentang performa masing-masing model.
    
    Hasil analisis ini tidak hanya mengidentifikasi model dengan performa terbaik, tetapi juga memberikan insights tentang fitur-fitur mana yang paling penting dalam memprediksi jenis cuaca. Kami juga menyediakan penjelasan yang dapat dipahami tentang bagaimana setiap algoritma membuat keputusan, serta membangun aplikasi prediction yang interaktif untuk mengklasifikasikan jenis cuaca secara real-time. Dengan kombinasi dari tools visualization, explanation, dan aplikasi interaktif, penelitian ini memberikan kontribusi dalam pengembangan sistem prediksi cuaca berbasis machine learning yang akurat dan interpretable.
    """)
    
    st.markdown("---")
    
    st.subheader("ÔøΩüìã Deskripsi Fitur")
    
    features_desc = {
        "Temperature": "Suhu dalam ¬∞C (dari sangat dingin hingga sangat panas)",
        "Humidity": "Kelembaban (%)",
        "Wind Speed": "Kecepatan angin (km/jam)",
        "Precipitation (%)": "Presipitasi (%)",
        "Cloud Cover": "Deskripsi tutupan awan",
        "Atmospheric Pressure": "Tekanan atmosfer (hPa)",
        "UV Index": "Indeks UV (0-11)",
        "Season": "Musim saat data direkam",
        "Visibility (km)": "Jarak pandang (km)",
        "Location": "Lokasi pengambilan data",
        "Weather Type": "üéØ Target - Jenis cuaca"
    }
    
    for feature, desc in features_desc.items():
        st.write(f"**{feature}:** {desc}")
    
    st.markdown("---")
    
    st.subheader("üìä Pratinjau Data")
    st.write("**5 Baris Pertama:**")
    st.dataframe(df.head(), use_container_width=True)
    
    st.write("**Statistik Deskriptif:**")
    st.dataframe(df.describe(), use_container_width=True)

# ====================== TAB 2: DASHBOARD ======================
with tab2:
    st.header("üìä Dashboard - Analisis Data Eksploratori")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üéØ Distribusi Tipe Cuaca")
        fig, ax = plt.subplots(figsize=(8, 5))
        weather_counts = df["Weather Type"].value_counts()
        colors = RED_TO_GOLD[:len(weather_counts)]
        ax.bar(weather_counts.index, weather_counts.values, color=colors, alpha=0.7, edgecolor=PRIMARY_COLOR)
        ax.set_ylabel("Jumlah", fontweight='bold')
        ax.set_title("Jumlah Data per Tipe Cuaca", fontweight='bold', color=PRIMARY_COLOR)
        ax.grid(axis='y', alpha=0.3)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    with col2:
        st.subheader("üìà Proporsi Tipe Cuaca")
        fig, ax = plt.subplots(figsize=(8, 5))
        weather_props = df["Weather Type"].value_counts(normalize=True) * 100
        colors = RED_TO_GOLD[:len(weather_props)]
        wedges, texts, autotexts = ax.pie(weather_props.values, labels=weather_props.index, autopct='%1.1f%%',
                                            colors=colors, startangle=90)
        ax.set_title("Proporsi Tipe Cuaca", fontweight='bold', color=PRIMARY_COLOR)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üå°Ô∏è Distribusi Suhu")
        fig, ax = plt.subplots(figsize=(8, 5))
        ax.hist(df["Temperature"], bins=30, color=SECONDARY_COLOR, alpha=0.7, edgecolor=PRIMARY_COLOR)
        ax.set_xlabel("Suhu (¬∞C)", fontweight='bold')
        ax.set_ylabel("Frekuensi", fontweight='bold')
        ax.set_title("Distribusi Suhu", fontweight='bold', color=PRIMARY_COLOR)
        ax.grid(axis='y', alpha=0.3)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    with col2:
        st.subheader("üí® Distribusi Kecepatan Angin")
        fig, ax = plt.subplots(figsize=(8, 5))
        ax.hist(df["Wind Speed"], bins=30, color=ACCENT_COLOR, alpha=0.7, edgecolor=PRIMARY_COLOR)
        ax.set_xlabel("Kecepatan Angin (km/jam)", fontweight='bold')
        ax.set_ylabel("Frekuensi", fontweight='bold')
        ax.set_title("Distribusi Kecepatan Angin", fontweight='bold', color=PRIMARY_COLOR)
        ax.grid(axis='y', alpha=0.3)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("‚òÅÔ∏è Distribusi Tutupan Awan per Tipe Cuaca")
        fig, ax = plt.subplots(figsize=(8, 5))
        cloud_weather = pd.crosstab(df["Cloud Cover"], df["Weather Type"])
        cloud_weather.plot(kind='bar', ax=ax, color=RED_TO_GOLD, alpha=0.8, edgecolor=PRIMARY_COLOR)
        ax.set_ylabel("Jumlah", fontweight='bold')
        ax.set_xlabel("Tutupan Awan", fontweight='bold')
        ax.set_title("Hubungan Tutupan Awan dengan Tipe Cuaca", fontweight='bold', color=PRIMARY_COLOR)
        ax.legend(title="Tipe Cuaca", bbox_to_anchor=(1.05, 1), loc='upper left')
        ax.grid(axis='y', alpha=0.3)
        fig.tight_layout()
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    with col2:
        st.subheader("‚òÄÔ∏è Distribusi Indeks UV per Tipe Cuaca")
        fig, ax = plt.subplots(figsize=(8, 5))
        weather_types = df["Weather Type"].unique()
        for i, weather in enumerate(weather_types):
            data = df[df["Weather Type"] == weather]["UV Index"]
            ax.hist(data, bins=20, alpha=0.6, label=weather, color=RED_TO_GOLD[i % len(RED_TO_GOLD)], edgecolor=PRIMARY_COLOR)
        ax.set_xlabel("Indeks UV", fontweight='bold')
        ax.set_ylabel("Frekuensi", fontweight='bold')
        ax.set_title("Distribusi Indeks UV per Tipe Cuaca", fontweight='bold', color=PRIMARY_COLOR)
        ax.legend()
        ax.grid(axis='y', alpha=0.3)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üçÇ Distribusi Musim")
        fig, ax = plt.subplots(figsize=(8, 5))
        season_counts = df["Season"].value_counts()
        colors = RED_TO_GOLD[:len(season_counts)]
        ax.bar(season_counts.index, season_counts.values, color=colors, alpha=0.7, edgecolor=PRIMARY_COLOR)
        ax.set_ylabel("Jumlah", fontweight='bold')
        ax.set_title("Jumlah Data per Musim", fontweight='bold', color=PRIMARY_COLOR)
        ax.grid(axis='y', alpha=0.3)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    with col2:
        st.subheader("üìç Distribusi Lokasi")
        fig, ax = plt.subplots(figsize=(8, 5))
        location_counts = df["Location"].value_counts()
        colors = RED_TO_GOLD[:len(location_counts)]
        ax.bar(location_counts.index, location_counts.values, color=colors, alpha=0.7, edgecolor=PRIMARY_COLOR)
        ax.set_ylabel("Jumlah", fontweight='bold')
        ax.set_title("Jumlah Data per Lokasi", fontweight='bold', color=PRIMARY_COLOR)
        ax.grid(axis='y', alpha=0.3)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    st.markdown("---")
    
    st.subheader("üíß Distribusi Kelembaban")
    fig, ax = plt.subplots(figsize=(12, 5))
    ax.hist(df["Humidity"], bins=30, color=SECONDARY_COLOR, alpha=0.7, edgecolor=PRIMARY_COLOR)
    ax.set_xlabel("Kelembaban (%)", fontweight='bold')
    ax.set_ylabel("Frekuensi", fontweight='bold')
    ax.set_title("Distribusi Kelembaban", fontweight='bold', color=PRIMARY_COLOR)
    ax.grid(axis='y', alpha=0.3)
    fig.patch.set_facecolor('white')
    st.pyplot(fig)
    
    st.markdown("---")
    
    # Distribution Analysis Explanations
    st.subheader("üìö Analisis Distribusi Fitur")
    
    st.markdown("""
    **‚òÅÔ∏è Cloud Cover (Tutupan Awan):**
    
    Kondisi tutupan awan sangat mempengaruhi jenis cuaca, dengan cuaca cerah yang cenderung terjadi pada kondisi langit yang lebih cerah dan cuaca hujan atau berawan yang terjadi pada kondisi mendung. Dari distribusi di atas, kita dapat melihat bahwa setiap kategori Cloud Cover memiliki asosiasi kuat dengan jenis cuaca tertentu. Kategori "Clear" mendominasi pada cuaca Sunny, sementara "Overcast" lebih sering dikaitkan dengan cuaca Rainy dan Cloudy.
    """)
    
    st.markdown("""
    **‚òÄÔ∏è UV Index (Indeks Ultraviolet):**
    
    UV Index menunjukkan seberapa kuat radiasi UV dari matahari. Ketika cuaca cerah, sinar matahari tidak terhalang, sehingga indeks UV cenderung lebih tinggi. Sebaliknya, ketika cuaca hujan, berawan, atau bersalju, awan dan partikel lainnya di atmosfer menghalangi sinar matahari, sehingga indeks UV menjadi lebih rendah. 
    
    Asumsi mengapa cuaca salju ada yang berdistribusi tinggi adalah sebagai berikut:
    - **Ketinggian lokasi:** Jika cuaca bersalju terjadi di daerah dataran yang tinggi, indeks UV juga bisa lebih tinggi karena semakin tinggi lokasi tempat, sinar UV lebih kuat.
    - **Refleksi dari salju:** Salju memiliki kemampuan untuk memantulkan sinar UV, sehingga meskipun cuaca mungkin berawan, sinar UV yang ada bisa dipantulkan dari permukaan salju dapat meningkatkan nilai indeks UV.
    """)
    
    st.markdown("""
    **üçÇ Season (Musim):**
    
    Musim mempengaruhi jenis cuaca yang dominan, dengan cuaca bersalju yang hampir eksklusif terjadi di musim dingin dan cuaca cerah lebih sering terjadi di musim panas. Distribusi musim dalam dataset menunjukkan variabilitas yang membantu model untuk mempelajari pola musiman dalam klasifikasi cuaca. Setiap musim membawa karakteristik cuaca yang unik dan dapat menjadi fitur prediktif yang kuat.
    """)
    
    st.markdown("""
    **üìç Location (Lokasi):**
    
    Lokasi geografis juga memiliki pengaruh signifikan, di mana daerah pegunungan lebih sering mengalami cuaca bersalju, sedangkan daerah pantai lebih banyak mengalami cuaca cerah dan berawan. Perbedaan distribusi lokasi menunjukkan bahwa model perlu mempertimbangkan konteks geografis untuk prediksi yang akurat. Lokasi Urban, Coastal, dan Rural masing-masing memiliki karakteristik cuaca yang berbeda.
    """)
    
    st.markdown("""
    **üå§Ô∏è Karakteristik Jenis Cuaca:**
    
    - **Cuaca Cerah (Sunny):** Cenderung terjadi pada suhu yang lebih tinggi dengan kelembaban dan curah hujan yang lebih rendah serta visibilitas yang paling baik. Indeks UV juga tinggi dan langit cenderung jelas (Clear).
    
    - **Cuaca Hujan (Rainy) dan Bersalju (Snowy):** Menunjukkan kelembaban tinggi, curah hujan yang signifikan, dan visibilitas yang lebih rendah, dengan suhu yang berkaitan dengan karakteristik masing-masing. Cuaca Rainy terjadi pada suhu sedang sementara Snowy pada suhu rendah.
    
    - **Cuaca Berawan (Cloudy):** Menunjukkan distribusi yang lebih bervariasi pada semua fitur, mencerminkan kondisi cuaca yang lebih beragam. Kategori ini menjadi transisi antara cuaca cerah dan cuaca ekstrem seperti hujan atau salju.
    """)

# ====================== TAB 3: MACHINE LEARNING ======================
with tab3:
    st.header("ü§ñ Machine Learning - Pelatihan & Evaluasi Model")
    
    # ===== 1. Dataset yang Digunakan =====
    st.subheader("1Ô∏è‚É£ Dataset yang Digunakan")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üìä Total Sampel", len(df))
    with col2:
        st.metric("üìã Jumlah Fitur", len(df.columns))
    with col3:
        st.metric("üéØ Kelas Target", len(df["Weather Type"].unique()))
    
    st.write("**Preview Data (10 Baris Pertama):**")
    st.dataframe(df.head(10), use_container_width=True)
    
    st.write("**Statistik Deskriptif Dataset:**")
    st.dataframe(df.describe(), use_container_width=True)
    
    st.markdown("---")
    
    # ===== 2. Visualisasi Boxplot Distribusi =====
    st.subheader("2Ô∏è‚É£ Visualisasi Boxplot Distribusi Data")
    
    numerical_cols = ["Temperature", "Humidity", "Wind Speed", "Precipitation (%)", 
                      "Atmospheric Pressure", "UV Index", "Visibility (km)"]
    
    fig, axes = plt.subplots(2, 4, figsize=(16, 8))
    axes = axes.flatten()
    
    for idx, col in enumerate(numerical_cols):
        axes[idx].boxplot([df[df["Weather Type"] == wtype][col].values for wtype in df["Weather Type"].unique()],
                          labels=df["Weather Type"].unique())
        axes[idx].set_title(f"Distribusi {col}", fontweight='bold', color=PRIMARY_COLOR)
        axes[idx].set_ylabel("Nilai", fontweight='bold')
        axes[idx].grid(axis='y', alpha=0.3)
        axes[idx].tick_params(axis='x', rotation=45)
    
    axes[-1].axis('off')
    fig.tight_layout()
    fig.patch.set_facecolor('white')
    st.pyplot(fig)
    
    st.markdown("---")
    
    # ===== 3. Normalisasi Data dengan Min-Max Scaling =====
    st.subheader("3Ô∏è‚É£ Normalisasi Data dengan Min-Max Scaling")
    
    from sklearn.preprocessing import MinMaxScaler
    
    minmax_scaler = MinMaxScaler()
    df_minmax = df.copy()
    df_minmax[numerical_cols] = minmax_scaler.fit_transform(df[numerical_cols])
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Sebelum Min-Max Scaling (Original)**")
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.boxplot([df[col].values for col in numerical_cols], labels=numerical_cols)
        ax.set_ylabel("Nilai", fontweight='bold')
        ax.set_title("Data Original (Range Berbeda)", fontweight='bold', color=PRIMARY_COLOR)
        ax.tick_params(axis='x', rotation=45)
        ax.grid(axis='y', alpha=0.3)
        fig.tight_layout()
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    with col2:
        st.write("**Setelah Min-Max Scaling**")
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.boxplot([df_minmax[col].values for col in numerical_cols], labels=numerical_cols)
        ax.set_ylabel("Nilai (0-1)", fontweight='bold')
        ax.set_title("Data Min-Max Scaled (Range 0-1)", fontweight='bold', color=PRIMARY_COLOR)
        ax.tick_params(axis='x', rotation=45)
        ax.grid(axis='y', alpha=0.3)
        fig.tight_layout()
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    st.info("""
    **Min-Max Scaling:** Mengubah data ke range [0, 1] dengan rumus: (X - min) / (max - min)
    - Semua fitur memiliki skala yang sama
    - Mempertahankan distribusi data asli
    - Cocok untuk: Neural Networks, KNN, K-Means
    """)
    
    st.markdown("---")
    
    # ===== 4. Analisis Korelasi Antar Variabel =====
    st.subheader("4Ô∏è‚É£ Analisis Korelasi Antar Variabel")
    
    # Prepare data for correlation (encode categorical variables temporarily)
    df_corr = df.copy()
    le_temp = LabelEncoder()
    df_corr["Cloud Cover"] = le_temp.fit_transform(df_corr["Cloud Cover"])
    le_temp2 = LabelEncoder()
    df_corr["Season"] = le_temp2.fit_transform(df_corr["Season"])
    le_temp3 = LabelEncoder()
    df_corr["Location"] = le_temp3.fit_transform(df_corr["Location"])
    le_temp4 = LabelEncoder()
    df_corr["Weather Type"] = le_temp4.fit_transform(df_corr["Weather Type"])
    
    correlation_matrix = df_corr.corr()
    
    fig, ax = plt.subplots(figsize=(12, 10))
    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,
                square=True, ax=ax, cbar_kws={'label': 'Korelasi'}, linewidths=0.5)
    ax.set_title("Matriks Korelasi Antar Variabel", fontweight='bold', color=PRIMARY_COLOR, fontsize=14)
    fig.tight_layout()
    fig.patch.set_facecolor('white')
    st.pyplot(fig)
    
    st.info("""
    **Interpretasi Korelasi:**
    - **Korelasi Positif (mendekati 1):** Dua variabel bergerak searah
    - **Korelasi Negatif (mendekati -1):** Dua variabel bergerak berlawanan arah
    - **Korelasi ~0:** Tidak ada hubungan linear antara variabel
    """)
    
    st.markdown("---")
    
    # ===== 5. Pembagian Data =====
    st.subheader("5Ô∏è‚É£ Pembagian Data (Train-Test Split)")
    
    # Data Preprocessing
    le = LabelEncoder()
    df_processed = df.copy()
    df_processed["Cloud Cover"] = le.fit_transform(df_processed["Cloud Cover"])
    df_processed["Season"] = le.fit_transform(df_processed["Season"])
    df_processed["Location"] = le.fit_transform(df_processed["Location"])
    
    scaler = StandardScaler()
    df_processed[numerical_cols] = scaler.fit_transform(df_processed[numerical_cols])
    
    le_target = LabelEncoder()
    y_encoded = le_target.fit_transform(df_processed["Weather Type"])
    X = df_processed.drop("Weather Type", axis=1)
    y = y_encoded
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üìä Total Data", len(df))
    with col2:
        st.metric("üéì Data Latihan (80%)", len(X_train))
    with col3:
        st.metric("üß™ Data Pengujian (20%)", len(X_test))
    
    # Visualisasi pembagian data
    fig, ax = plt.subplots(figsize=(8, 5))
    sizes = [len(X_train), len(X_test)]
    labels = [f'Data Latihan\n({len(X_train)} sampel)', f'Data Pengujian\n({len(X_test)} sampel)']
    colors = [PRIMARY_COLOR, SECONDARY_COLOR]
    ax.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90, textprops={'fontsize': 12, 'weight': 'bold'})
    ax.set_title("Pembagian Data Train-Test", fontweight='bold', color=PRIMARY_COLOR, fontsize=14)
    fig.patch.set_facecolor('white')
    st.pyplot(fig)
    
    st.markdown("---")
    
    # ===== 6. Pemilihan Model Klasifikasi =====
    st.subheader("6Ô∏è‚É£ Pemilihan Model Klasifikasi")
    
    model_option = st.selectbox(
        "Pilih satu model untuk analisis detail:",
        ("Logistic Regression", "Random Forest", "Gaussian Naive Bayes", "SVM", "Gradient Boosting")
    )
    
    # Model Descriptions
    model_descriptions = {
        "Logistic Regression": "üîµ Algoritma linear yang menggunakan fungsi sigmoid untuk memprediksi probabilitas kelas.",
        "Random Forest": "üå≥ Ensemble learning yang menggabungkan banyak decision trees untuk prediksi yang lebih robust.",
        "Gaussian Naive Bayes": "üé≤ Probabilistic classifier berbasis Bayes dengan asumsi fitur independen.",
        "SVM": "üìç Mencari hyperplane optimal untuk memaksimalkan margin antar kelas.",
        "Gradient Boosting": "üìà Sequential ensemble yang membangun trees untuk meminimalkan error secara bertahap."
    }
    
    st.info(model_descriptions[model_option])
    
    # Model Initialization
    if model_option == "Logistic Regression":
        model = LogisticRegression(max_iter=1000)
    elif model_option == "Random Forest":
        model = RandomForestClassifier(n_estimators=100, random_state=42)
    elif model_option == "Gaussian Naive Bayes":
        model = GaussianNB()
    elif model_option == "SVM":
        model = SVC(probability=True, random_state=42)
    elif model_option == "Gradient Boosting":
        model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
    
    # Train Model
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    st.markdown("---")
    
    # ===== 7. Evaluasi Model dan Perbandingan Peforma Semua Model =====
    st.subheader("7Ô∏è‚É£ Evaluasi Model & Perbandingan Peforma Semua Model")
    
    # Current model metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision_avg = precision_score(y_test, y_pred, average='weighted')
    recall_avg = recall_score(y_test, y_pred, average='weighted')
    f1_avg = f1_score(y_test, y_pred, average='weighted')
    
    st.write(f"**Metrik Model Terpilih: {model_option}**")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üéØ Akurasi", f"{accuracy:.4f}")
    with col2:
        st.metric("üìä Presisi", f"{precision_avg:.4f}")
    with col3:
        st.metric("üîç Recall", f"{recall_avg:.4f}")
    with col4:
        st.metric("‚ö° F1-Score", f"{f1_avg:.4f}")
    
    st.markdown("---")
    
    # Train all models for comparison
    st.write("**Perbandingan Peforma Semua Model:**")
    
    models_dict = {
        "Logistic Regression": LogisticRegression(max_iter=1000),
        "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
        "Gaussian Naive Bayes": GaussianNB(),
        "SVM": SVC(probability=True, random_state=42),
        "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
    }
    
    results_list = []
    for model_name, model_obj in models_dict.items():
        model_obj.fit(X_train, y_train)
        y_pred_temp = model_obj.predict(X_test)
        
        acc = accuracy_score(y_test, y_pred_temp)
        prec = precision_score(y_test, y_pred_temp, average='weighted')
        rec = recall_score(y_test, y_pred_temp, average='weighted')
        f1 = f1_score(y_test, y_pred_temp, average='weighted')
        
        results_list.append({
            "Model": model_name,
            "Akurasi": f"{acc:.4f}",
            "Presisi": f"{prec:.4f}",
            "Recall": f"{rec:.4f}",
            "F1-Score": f"{f1:.4f}"
        })
    
    results_df = pd.DataFrame(results_list)
    st.dataframe(results_df, use_container_width=True)
    
    # Visualisasi perbandingan
    fig, ax = plt.subplots(figsize=(12, 6))
    
    # Convert for plotting
    results_plot = results_df.copy()
    for col in ["Akurasi", "Presisi", "Recall", "F1-Score"]:
        results_plot[col] = results_plot[col].astype(float)
    
    x = np.arange(len(results_plot))
    width = 0.2
    
    ax.bar(x - 1.5*width, results_plot["Akurasi"], width, label="Akurasi", color=RED_TO_GOLD[0], alpha=0.8)
    ax.bar(x - 0.5*width, results_plot["Presisi"], width, label="Presisi", color=RED_TO_GOLD[1], alpha=0.8)
    ax.bar(x + 0.5*width, results_plot["Recall"], width, label="Recall", color=RED_TO_GOLD[2], alpha=0.8)
    ax.bar(x + 1.5*width, results_plot["F1-Score"], width, label="F1-Score", color=RED_TO_GOLD[3], alpha=0.8)
    
    ax.set_ylabel("Skor", fontweight='bold')
    ax.set_title("Perbandingan Metrik Semua Model", fontweight='bold', color=PRIMARY_COLOR, fontsize=14)
    ax.set_xticks(x)
    ax.set_xticklabels(results_plot["Model"], rotation=45, ha='right')
    ax.legend()
    ax.set_ylim([0, 1])
    ax.grid(axis='y', alpha=0.3)
    
    fig.tight_layout()
    fig.patch.set_facecolor('white')
    st.pyplot(fig)
    
    # Confusion Matrix
    st.write(f"**Matriks Kebingungan - {model_option}:**")
    class_labels = le_target.classes_
    cm = confusion_matrix(y_test, y_pred)
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='RdYlGn', xticklabels=class_labels,
                yticklabels=class_labels, ax=ax, cbar_kws={'label': 'Jumlah'})
    ax.set_ylabel('Label Sebenarnya', fontweight='bold')
    ax.set_xlabel('Label Prediksi', fontweight='bold')
    ax.set_title(f'Matriks Kebingungan - {model_option}', fontweight='bold', color=PRIMARY_COLOR)
    fig.patch.set_facecolor('white')
    st.pyplot(fig)
    
    st.markdown("---")
    
    # ===== 8. Feature Importance =====
    st.subheader("8Ô∏è‚É£ Feature Importance (Kepentingan Fitur)")
    
    if model_option in ["Random Forest", "Gradient Boosting"]:
        feature_importance_values = model.feature_importances_
        feature_names = X_train.columns
        
        importance_df = pd.DataFrame({
            'Fitur': feature_names,
            'Kepentingan': feature_importance_values
        }).sort_values('Kepentingan', ascending=False)
        
        fig, ax = plt.subplots(figsize=(10, 6))
        colors = RED_TO_GOLD[:len(importance_df)]
        ax.barh(importance_df['Fitur'], importance_df['Kepentingan'], color=colors, alpha=0.7, edgecolor=PRIMARY_COLOR)
        ax.set_xlabel('Kepentingan (Importance Score)', fontweight='bold')
        ax.set_title(f'Feature Importance - {model_option}', fontweight='bold', color=PRIMARY_COLOR, fontsize=12)
        ax.invert_yaxis()
        ax.grid(axis='x', alpha=0.3)
        fig.tight_layout()
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
        
        st.dataframe(importance_df, use_container_width=True)
        
    elif model_option == "Logistic Regression":
        coef_values = model.coef_[0]
        feature_names = X_train.columns
        
        coef_df = pd.DataFrame({
            'Fitur': feature_names,
            'Koefisien': coef_values
        }).sort_values('Koefisien', key=abs, ascending=False)
        
        fig, ax = plt.subplots(figsize=(10, 6))
        colors = [SECONDARY_COLOR if x > 0 else ACCENT_COLOR for x in coef_df['Koefisien']]
        ax.barh(coef_df['Fitur'], coef_df['Koefisien'], color=colors, alpha=0.7, edgecolor=PRIMARY_COLOR)
        ax.set_xlabel('Koefisien (Positive=Meningkatkan, Negative=Menurunkan)', fontweight='bold')
        ax.set_title('Feature Coefficients - Logistic Regression', fontweight='bold', color=PRIMARY_COLOR, fontsize=12)
        ax.invert_yaxis()
        ax.grid(axis='x', alpha=0.3)
        fig.tight_layout()
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
        
        st.dataframe(coef_df, use_container_width=True)
        
    else:
        st.warning("‚ö†Ô∏è Model ini tidak memiliki feature importance yang dapat divisualisasikan langsung.")
    
    st.markdown("---")
    
    # ===== 9. Interpretasi Feature Importance =====
    st.subheader("9Ô∏è‚É£ Analisis & Interpretasi Feature Importance")
    
    if model_option in ["Random Forest", "Gradient Boosting"]:
        importance_df_sorted = pd.DataFrame({
            'Fitur': X_train.columns,
            'Kepentingan': model.feature_importances_
        }).sort_values('Kepentingan', ascending=False)
        
        st.write("**üìå Penjelasan Feature Importance:**")
        st.write("""
        **Feature Importance** menunjukkan seberapa besar kontribusi setiap fitur dalam membuat prediksi model.
        Semakin tinggi nilai kepentingan, semakin penting fitur tersebut untuk klasifikasi jenis cuaca.
        """)
        
        st.markdown("---")
        
        st.write("**üìä Analisis Mendalam Berdasarkan Data:**")
        
        # Top 5 features analysis
        top_5 = importance_df_sorted.head(5)
        
        st.write(f"**Top 5 Fitur Paling Penting ({model_option}):**")
        for rank, (idx, row) in enumerate(top_5.iterrows(), 1):
            percentage = row['Kepentingan'] * 100
            col1, col2 = st.columns([1, 3])
            with col1:
                st.metric(f"üîù Rank {rank}", f"{percentage:.2f}%")
            with col2:
                st.write(f"**{row['Fitur']}**")
        
        st.markdown("---")
        
        # Analisis per fitur top
        st.write("**üîç Analisis Detail Fitur Teratas:**")
        
        # Analisis top fitur 1
        top_feature_1 = importance_df_sorted.iloc[0]['Fitur']
        top_feature_1_importance = importance_df_sorted.iloc[0]['Kepentingan'] * 100
        
        st.write(f"**1. {top_feature_1} ({top_feature_1_importance:.2f}%)**")
        
        # Analisis distribusi fitur 1 per weather type
        fig, ax = plt.subplots(figsize=(10, 5))
        for weather in df["Weather Type"].unique():
            data = df[df["Weather Type"] == weather][top_feature_1]
            ax.hist(data, alpha=0.6, label=weather, bins=15)
        ax.set_xlabel(top_feature_1, fontweight='bold')
        ax.set_ylabel('Frekuensi', fontweight='bold')
        ax.set_title(f'Distribusi {top_feature_1} per Jenis Cuaca', fontweight='bold', color=PRIMARY_COLOR)
        ax.legend()
        ax.grid(alpha=0.3)
        fig.tight_layout()
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
        
        # Statistik per weather type
        stats_data = []
        for weather in df["Weather Type"].unique():
            data = df[df["Weather Type"] == weather][top_feature_1]
            stats_data.append({
                'Cuaca': weather,
                'Mean': f"{data.mean():.2f}",
                'Std Dev': f"{data.std():.2f}",
                'Min': f"{data.min():.2f}",
                'Max': f"{data.max():.2f}"
            })
        
        st.write("**Statistik per Jenis Cuaca:**")
        st.dataframe(pd.DataFrame(stats_data), use_container_width=True)
        
        insight_1 = f"""
        **Insight:** Fitur {top_feature_1} adalah yang paling penting ({top_feature_1_importance:.2f}%) karena memiliki 
        variasi yang signifikan antar jenis cuaca. Model menggunakan fitur ini sebagai pembeda utama untuk 
        mengklasifikasikan jenis cuaca. Nilai {top_feature_1} yang berbeda antar cuaca membantu model membuat keputusan 
        klasifikasi yang akurat.
        """
        st.success(insight_1)
        
        st.markdown("---")
        
        # Analisis top fitur 2
        if len(importance_df_sorted) > 1:
            top_feature_2 = importance_df_sorted.iloc[1]['Fitur']
            top_feature_2_importance = importance_df_sorted.iloc[1]['Kepentingan'] * 100
            
            st.write(f"**2. {top_feature_2} ({top_feature_2_importance:.2f}%)**")
            
            fig, ax = plt.subplots(figsize=(10, 5))
            for weather in df["Weather Type"].unique():
                data = df[df["Weather Type"] == weather][top_feature_2]
                ax.hist(data, alpha=0.6, label=weather, bins=15)
            ax.set_xlabel(top_feature_2, fontweight='bold')
            ax.set_ylabel('Frekuensi', fontweight='bold')
            ax.set_title(f'Distribusi {top_feature_2} per Jenis Cuaca', fontweight='bold', color=PRIMARY_COLOR)
            ax.legend()
            ax.grid(alpha=0.3)
            fig.tight_layout()
            fig.patch.set_facecolor('white')
            st.pyplot(fig)
            
            stats_data_2 = []
            for weather in df["Weather Type"].unique():
                data = df[df["Weather Type"] == weather][top_feature_2]
                stats_data_2.append({
                    'Cuaca': weather,
                    'Mean': f"{data.mean():.2f}",
                    'Std Dev': f"{data.std():.2f}",
                    'Min': f"{data.min():.2f}",
                    'Max': f"{data.max():.2f}"
                })
            
            st.write("**Statistik per Jenis Cuaca:**")
            st.dataframe(pd.DataFrame(stats_data_2), use_container_width=True)
            
            insight_2 = f"""
            **Insight:** Fitur {top_feature_2} ({top_feature_2_importance:.2f}%) juga memainkan peran penting sebagai 
            fitur pendukung dalam klasifikasi. Kombinasi antara {top_feature_1} dan {top_feature_2} memberikan sinyal 
            yang kuat untuk model dalam membedakan berbagai jenis cuaca.
            """
            st.success(insight_2)
        
        st.markdown("---")
        
        # Analisis fitur dengan importance rendah
        st.write("**üìâ Fitur Dengan Kepentingan Rendah:**")
        
        low_importance = importance_df_sorted.tail(3)
        
        low_features_text = ""
        for idx, row in low_importance.iterrows():
            percentage = row['Kepentingan'] * 100
            low_features_text += f"- **{row['Fitur']}**: {percentage:.2f}%\n"
        
        st.write(low_features_text)
        
        low_insight = """
        **Insight:** Fitur-fitur dengan kepentingan rendah ini memiliki kontribusi minimal terhadap klasifikasi.
        Hal ini bisa terjadi karena:
        1. Fitur tersebut tidak memiliki variasi signifikan antar jenis cuaca
        2. Fitur sudah tercakup oleh informasi fitur-fitur penting lainnya
        3. Korelasi fitur dengan target variable rendah
        """
        st.info(low_insight)
        
        st.markdown("---")
        
        # Summary analysis
        st.write("**üéØ Kesimpulan Analisis:**")
        
        summary = f"""
        1. **Fitur Dominan**: Model {model_option} sangat mengandalkan {importance_df_sorted.iloc[0]['Fitur']} 
           dan {importance_df_sorted.iloc[1]['Fitur']} untuk klasifikasi.
        
        2. **Hubungan dengan Target**: Kedua fitur ini menunjukkan pola distribusi yang jelas antar jenis cuaca,
           membuatnya ideal untuk prediksi.
        
        3. **Implikasi Praktis**:
           - Pastikan akurasi pengumpulan data untuk fitur-fitur penting
           - Fitur dengan kepentingan rendah bisa dikurangi untuk efisiensi (feature reduction)
           - Model ini dapat diandalkan karena keputusannya berdasarkan fitur yang secara logis relevan dengan cuaca
        
        4. **Validasi Logis**: Fitur-fitur dengan kepentingan tinggi adalah yang secara intuitif paling mempengaruhi
           jenis cuaca (suhu, kelembaban, dll), sehingga hasil analisis model sesuai dengan pengetahuan domain.
        """
        
        st.success(summary)
        
    elif model_option == "Logistic Regression":
        coef_df_sorted = pd.DataFrame({
            'Fitur': X_train.columns,
            'Koefisien': model.coef_[0]
        }).sort_values('Koefisien', key=abs, ascending=False)
        
        st.write("**üìå Penjelasan Koefisien Logistic Regression:**")
        st.write("""
        **Koefisien** menunjukkan arah dan kekuatan pengaruh fitur terhadap probabilitas prediksi kelas.
        - **Koefisien Positif**: Peningkatan fitur meningkatkan probabilitas kelas prediksi
        - **Koefisien Negatif**: Peningkatan fitur menurunkan probabilitas kelas prediksi
        - **Magnitude**: Semakin besar |koefisien|, semakin kuat pengaruh fitur
        """)
        
        st.markdown("---")
        
        st.write("**üìä Analisis Mendalam Koefisien:**")
        
        top_5_coef = coef_df_sorted.head(5)
        
        st.write("**Top 5 Fitur Paling Berpengaruh:**")
        for rank, (idx, row) in enumerate(top_5_coef.iterrows(), 1):
            direction = "üìà Positif" if row['Koefisien'] > 0 else "üìâ Negatif"
            col1, col2 = st.columns([1, 3])
            with col1:
                st.metric(f"#{rank}", f"{row['Koefisien']:.4f}")
            with col2:
                st.write(f"{direction} **{row['Fitur']}**")
        
        st.markdown("---")
        
        st.write("**üîç Analisis Pengaruh Fitur:**")
        
        # Analisis fitur dengan koefisien terbesar positif
        positive_coefs = coef_df_sorted[coef_df_sorted['Koefisien'] > 0].head(3)
        negative_coefs = coef_df_sorted[coef_df_sorted['Koefisien'] < 0].head(3)
        
        st.write("**Fitur dengan Pengaruh Positif TERKUAT:**")
        
        if len(positive_coefs) > 0:
            for idx, row in positive_coefs.iterrows():
                st.write(f"‚úÖ **{row['Fitur']}** (Koef: {row['Koefisien']:.4f})")
                st.write(f"   ‚Üí Semakin tinggi {row['Fitur']}, semakin meningkat probabilitas prediksi terhadap kelas target")
                
                # Analisis korelasi dengan target
                corr_with_target = df_corr[row['Fitur']].corr(df_corr['Weather Type'])
                st.write(f"   ‚Üí Korelasi dengan Weather Type: {corr_with_target:.3f}")
        
        st.write("**Fitur dengan Pengaruh Negatif TERKUAT:**")
        
        if len(negative_coefs) > 0:
            for idx, row in negative_coefs.iterrows():
                st.write(f"‚ùå **{row['Fitur']}** (Koef: {row['Koefisien']:.4f})")
                st.write(f"   ‚Üí Semakin tinggi {row['Fitur']}, semakin menurun probabilitas prediksi terhadap kelas target")
                
                corr_with_target = df_corr[row['Fitur']].corr(df_corr['Weather Type'])
                st.write(f"   ‚Üí Korelasi dengan Weather Type: {corr_with_target:.3f}")
        
        st.markdown("---")
        
        # Summary for logistic regression
        st.write("**üéØ Kesimpulan Analisis Logistic Regression:**")
        
        summary_lr = f"""
        1. **Model Linear**: Logistic Regression mengasumsikan hubungan linear antara fitur dan target.
           Koefisien menunjukkan hubungan ini secara eksplisit.
        
        2. **Fitur Paling Berpengaruh**: 
           - {top_5_coef.iloc[0]['Fitur']} memiliki pengaruh terkuat dengan koef {top_5_coef.iloc[0]['Koefisien']:.4f}
           - Perubahan pada fitur ini paling signifikan mempengaruhi prediksi
        
        3. **Interpretabilitas**: Koefisien positif dan negatif memberi informasi arah hubungan:
           - Positif: Peningkatan fitur ‚Üí peningkatan probabilitas kelas
           - Negatif: Peningkatan fitur ‚Üí penurunan probabilitas kelas
        
        4. **Keandalan Model**: Fitur-fitur dengan koefisien besar menunjukkan hubungan kuat dengan
           target variable, mengindikasikan model memiliki dasar logis untuk prediksi.
        """
        
        st.success(summary_lr)
    
    else:
        st.write("**Model ini memiliki analisis khusus - detail ditampilkan di visualisasi sebelumnya.**")
    
    st.markdown("---")
    
    st.markdown("---")
    
    st.subheader("üìä Visualisasi Data Cleaning & Preprocessing")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Sebelum Preprocessing (Data Mentah)**")
        fig, ax = plt.subplots(figsize=(8, 5))
        numerical_cols_raw = ["Temperature", "Humidity", "Wind Speed", "Precipitation (%)", 
                              "Atmospheric Pressure", "UV Index", "Visibility (km)"]
        ax.boxplot([df[col].values for col in numerical_cols_raw], labels=numerical_cols_raw)
        ax.set_ylabel("Nilai", fontweight='bold')
        ax.set_title("Data Numerik Sebelum Scaling", fontweight='bold', color=PRIMARY_COLOR)
        ax.tick_params(axis='x', rotation=45)
        fig.tight_layout()
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    with col2:
        st.write("**Setelah Preprocessing (Data Terskalakan)**")
        fig, ax = plt.subplots(figsize=(8, 5))
        ax.boxplot([df_processed[col].values for col in numerical_cols], labels=numerical_cols)
        ax.set_ylabel("Nilai Terskalakan", fontweight='bold')
        ax.set_title("Data Numerik Setelah Standardisasi", fontweight='bold', color=PRIMARY_COLOR)
        ax.tick_params(axis='x', rotation=45)
        fig.tight_layout()
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Fitur Kategorikal Sebelum Encoding**")
        fig, axes = plt.subplots(1, 3, figsize=(15, 4))
        categorical_cols = ["Cloud Cover", "Season", "Location"]
        for idx, col in enumerate(categorical_cols):
            counts = df[col].value_counts()
            colors = RED_TO_GOLD[:len(counts)]
            axes[idx].bar(counts.index, counts.values, color=colors, alpha=0.7, edgecolor=PRIMARY_COLOR)
            axes[idx].set_title(f"Distribusi {col}", fontweight='bold', color=PRIMARY_COLOR)
            axes[idx].set_ylabel("Jumlah", fontweight='bold')
            axes[idx].tick_params(axis='x', rotation=45)
            axes[idx].grid(axis='y', alpha=0.3)
        fig.tight_layout()
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    with col2:
        st.write("**Fitur Kategorikal Setelah Encoding**")
        fig, axes = plt.subplots(1, 3, figsize=(15, 4))
        for idx, col in enumerate(categorical_cols):
            encoded_vals = df_processed[col].value_counts().sort_index()
            colors = RED_TO_GOLD[:len(encoded_vals)]
            axes[idx].bar(encoded_vals.index, encoded_vals.values, color=colors, alpha=0.7, edgecolor=PRIMARY_COLOR)
            axes[idx].set_title(f"Encoded {col}", fontweight='bold', color=PRIMARY_COLOR)
    
    # Per-Class Metrics
    st.subheader("üìä Metrik per Kelas")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write("**Precision per Kelas:**")
        precision_scores = precision_score(y_test, y_pred, average=None)
        fig, ax = plt.subplots(figsize=(8, 5))
        colors_precision = RED_TO_GOLD[:len(class_labels)]
        ax.bar(class_labels, precision_scores, color=colors_precision, alpha=0.6, edgecolor=PRIMARY_COLOR)
        ax.set_ylabel('Precision', fontweight='bold')
        ax.set_ylim([0, 1])
        ax.grid(axis='y', alpha=0.3)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    with col2:
        st.write("**Recall per Kelas:**")
        recall_scores = recall_score(y_test, y_pred, average=None)
        fig, ax = plt.subplots(figsize=(8, 5))
        colors_recall = RED_TO_GOLD[:len(class_labels)]
        ax.bar(class_labels, recall_scores, color=colors_recall, alpha=0.6, edgecolor=PRIMARY_COLOR)
        ax.set_ylabel('Recall', fontweight='bold')
        ax.set_ylim([0, 1])
        ax.grid(axis='y', alpha=0.3)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    with col3:
        st.write("**F1-Score per Kelas:**")
        f1_scores = f1_score(y_test, y_pred, average=None)
        fig, ax = plt.subplots(figsize=(8, 5))
        colors_f1 = RED_TO_GOLD[:len(class_labels)]
        ax.bar(class_labels, f1_scores, color=colors_f1, alpha=0.6, edgecolor=PRIMARY_COLOR)
        ax.set_ylabel('F1-Score', fontweight='bold')
        ax.set_ylim([0, 1])
        ax.grid(axis='y', alpha=0.3)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    # Algorithm-Specific Visualizations
    st.markdown("---")
    st.subheader("üî¨ Visualisasi Spesifik Algoritma")
    
    if model_option == "Logistic Regression":
        st.write("**Koefisien Fitur:**")
        coef_df = pd.DataFrame({
            'Feature': X_train.columns,
            'Coefficient': model.coef_[0]
        }).sort_values('Coefficient', key=abs, ascending=False)
        
        fig, ax = plt.subplots(figsize=(10, 6))
        colors = [SECONDARY_COLOR if x > 0 else ACCENT_COLOR for x in coef_df['Coefficient']]
        ax.barh(coef_df['Feature'], coef_df['Coefficient'], color=colors, alpha=0.6, edgecolor=PRIMARY_COLOR)
        ax.set_xlabel('Nilai Koefisien', fontweight='bold')
        ax.set_title('Koefisien Fitur - Logistic Regression', fontweight='bold', color=PRIMARY_COLOR)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    elif model_option == "Random Forest":
        st.write("**Kepentingan Fitur (Top 10):**")
        feature_importance = pd.DataFrame({
            'Feature': X_train.columns,
            'Importance': model.feature_importances_
        }).sort_values('Importance', ascending=False).head(10)
        
        fig, ax = plt.subplots(figsize=(10, 6))
        colors_importance = RED_TO_GOLD[:len(feature_importance)]
        ax.barh(feature_importance['Feature'], feature_importance['Importance'], color=colors_importance, alpha=0.6, edgecolor=PRIMARY_COLOR)
        ax.set_xlabel('Kepentingan', fontweight='bold')
        ax.set_title('Top 10 Kepentingan Fitur - Random Forest', fontweight='bold', color=PRIMARY_COLOR)
        ax.invert_yaxis()
        ax.grid(axis='x', alpha=0.3)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    elif model_option == "Gradient Boosting":
        st.write("**Kepentingan Fitur (Top 10):**")
        feature_importance = pd.DataFrame({
            'Feature': X_train.columns,
            'Importance': model.feature_importances_
        }).sort_values('Importance', ascending=False).head(10)
        
        fig, ax = plt.subplots(figsize=(10, 6))
        colors_importance = RED_TO_GOLD[:len(feature_importance)]
        ax.barh(feature_importance['Feature'], feature_importance['Importance'], color=colors_importance, alpha=0.6, edgecolor=PRIMARY_COLOR)
        ax.set_xlabel('Kepentingan', fontweight='bold')
        ax.set_title('Top 10 Kepentingan Fitur - Gradient Boosting', fontweight='bold', color=PRIMARY_COLOR)
        ax.invert_yaxis()
        ax.grid(axis='x', alpha=0.3)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    elif model_option == "Gaussian Naive Bayes":
        st.write("**Probabilitas Prior (P(Kelas)):**")
        class_counts = pd.Series(y_train).value_counts().sort_index()
        prior_probs = class_counts / len(y_train)
        prior_probs.index = class_labels
        
        fig, ax = plt.subplots(figsize=(8, 5))
        colors_prior = RED_TO_GOLD[:len(class_labels)]
        ax.bar(class_labels, prior_probs.values, color=colors_prior, alpha=0.6, edgecolor=PRIMARY_COLOR)
        ax.set_ylabel('Probabilitas Prior', fontweight='bold')
        ax.set_title('Probabilitas Prior - Gaussian Naive Bayes', fontweight='bold', color=PRIMARY_COLOR)
        ax.set_ylim([0, max(prior_probs.values) * 1.2])
        ax.grid(axis='y', alpha=0.3)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    elif model_option == "SVM":
        st.write("**Vektor Pendukung per Kelas:**")
        support_info = pd.DataFrame({
            'Class': class_labels,
            'N Support Vectors': [model.n_support_[i] for i in range(len(class_labels))]
        })
        
        fig, ax = plt.subplots(figsize=(8, 5))
        colors_sv = RED_TO_GOLD[:len(class_labels)]
        ax.bar(support_info['Class'], support_info['N Support Vectors'], color=colors_sv, alpha=0.6, edgecolor=PRIMARY_COLOR)
        ax.set_ylabel('Jumlah', fontweight='bold')
        ax.set_title('Vektor Pendukung per Kelas - SVM', fontweight='bold', color=PRIMARY_COLOR)
        ax.grid(axis='y', alpha=0.3)
        fig.patch.set_facecolor('white')
        st.pyplot(fig)
    
    # ROC Curve
    st.markdown("---")
    st.subheader("üìà ROC Curve")
    
    if hasattr(model, 'predict_proba'):
        y_test_bin = label_binarize(y_test, classes=np.unique(y_test))
        y_pred_proba = model.predict_proba(X_test)
        
        fig, ax = plt.subplots(figsize=(10, 8))
        colors_roc = RED_TO_GOLD[:len(class_labels)]
        for i, class_name in enumerate(class_labels):
            fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])
            roc_auc = auc(fpr, tpr)
            ax.plot(fpr, tpr, label=f'{class_name} (AUC = {roc_auc:.3f})', color=colors_roc[i], linewidth=2)
        
        ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)
        ax.set_xlabel('False Positive Rate', fontweight='bold')
        ax.set_ylabel('True Positive Rate', fontweight='bold')
        ax.set_title(f'ROC Curve - {model_option}', fontweight='bold', color=PRIMARY_COLOR)
        ax.legend(loc='lower right')
        ax.grid(alpha=0.3)
        ax.set_facecolor('#f8f9fa')
        fig.patch.set_facecolor('white')
        st.pyplot(fig)

# ====================== TAB 4: BEST MODEL COMPARISON ======================
with tab4:
    st.header("üèÜ Cara Kerja Model Terbaik")
    
    st.info("Tab ini menampilkan perbandingan model dan langkah-langkah cara kerja model terbaik (Gradient Boosting) berdasarkan hasil analisis.")
    
    # Data Preprocessing untuk semua model
    le = LabelEncoder()
    df_processed = df.copy()
    df_processed["Cloud Cover"] = le.fit_transform(df_processed["Cloud Cover"])
    df_processed["Season"] = le.fit_transform(df_processed["Season"])
    df_processed["Location"] = le.fit_transform(df_processed["Location"])
    
    scaler = StandardScaler()
    numerical_cols = ["Temperature", "Humidity", "Wind Speed", "Precipitation (%)", 
                      "Atmospheric Pressure", "UV Index", "Visibility (km)"]
    df_processed[numerical_cols] = scaler.fit_transform(df_processed[numerical_cols])
    
    le_target = LabelEncoder()
    y_encoded = le_target.fit_transform(df_processed["Weather Type"])
    X = df_processed.drop("Weather Type", axis=1)
    y = y_encoded
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Train semua model
    models = {
        "Logistic Regression": LogisticRegression(max_iter=1000),
        "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
        "Gaussian Naive Bayes": GaussianNB(),
        "SVM": SVC(probability=True, random_state=42),
        "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
    }
    
    results = []
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        results.append({"Model": name, "Accuracy": f"{accuracy:.4f}"})
    
    # Tampilkan Hasil
    results_df = pd.DataFrame(results).sort_values("Accuracy", ascending=False)
    
    st.subheader("üìä Perbandingan Akurasi Model")
    st.dataframe(results_df, use_container_width=True)
    
    # Visualisasi
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # Convert accuracy to float for plotting
    results_for_plot = results_df.copy()
    results_for_plot["Accuracy"] = results_for_plot["Accuracy"].astype(float)
    results_for_plot = results_for_plot.sort_values("Accuracy", ascending=True)
    
    colors = RED_TO_GOLD[:len(results_for_plot)]
    ax.barh(results_for_plot["Model"], results_for_plot["Accuracy"], color=colors, alpha=0.7, edgecolor=PRIMARY_COLOR)
    ax.set_xlabel("Accuracy", fontweight='bold')
    ax.set_title("Perbandingan Akurasi Semua Model", fontweight='bold', color=PRIMARY_COLOR, fontsize=14)
    ax.set_xlim([0, 1])
    ax.grid(axis='x', alpha=0.3)
    
    # Add value labels
    for i, v in enumerate(results_for_plot["Accuracy"]):
        ax.text(v + 0.01, i, f'{v:.4f}', va='center', fontweight='bold')
    
    fig.patch.set_facecolor('white')
    st.pyplot(fig)
    
    # Best Model Recommendation
    best_model = results_df.iloc[0]
    st.success(f"üèÜ **Model Terbaik:** {best_model['Model']} (Akurasi: {best_model['Accuracy']})")
    
    st.markdown("---")
    
    # Langkah-langkah Cara Kerja Model Terbaik
    st.subheader("‚öôÔ∏è Langkah-Langkah Cara Kerja Model Terbaik: Gradient Boosting")
    
    st.markdown("""
    ### üìã Ringkasan Gradient Boosting
    
    **Gradient Boosting** dipilih sebagai model terbaik karena:
    - ‚úÖ Akurasi tertinggi dalam mengenali pola cuaca
    - ‚úÖ Mampu menangani kompleksitas data non-linear
    - ‚úÖ Robust terhadap outlier dan overfitting
    - ‚úÖ Stabil dan konsisten dalam prediksi
    
    ---
    
    ### üîÑ Langkah-Langkah Cara Kerja:
    
    **Langkah 1: Persiapan Data**
    - Input data mentah dengan 11 fitur cuaca (suhu, kelembaban, angin, dll.)
    - Encoding fitur kategorikal (Cloud Cover, Season, Location) menjadi nilai numerik
    - Standardisasi fitur numerik ke skala yang sama (0-1) menggunakan MinMaxScaler
    - Hasil: Dataset siap untuk training dengan distribusi fitur yang seimbang
    
    **Langkah 2: Feature Engineering**
    - Analisis kepentingan fitur dari data historis
    - Fitur utama yang mempengaruhi: Temperature, Humidity, Precipitation
    - Fitur pendukung: Cloud Cover, Season, Location, UV Index
    - Visualisasi: Distribusi fitur per jenis cuaca untuk mendeteksi pola unik
    
    **Langkah 3: Pemilihan Hyperparameter**
    - **N_estimators = 100**: Menggunakan 100 pohon keputusan yang dibangun secara sekuensial
    - **Learning rate = 0.1**: Kecepatan belajar terkontrol untuk menghindari overfitting
    - **Max_depth = 5**: Kedalaman pohon dibatasi untuk menjaga keseimbangan bias-variance
    - Configurasi ini dipilih berdasarkan cross-validation dan analisis performa
    
    **Langkah 4: Training Model**
    - Algoritma membangun pohon 1 dengan semua data (initial prediction)
    - Menghitung residual (error) dari prediksi pohon 1
    - Pohon 2 mempelajari pola dari residual pohon 1
    - Proses berulang 100 kali, setiap pohon baru memperbaiki error sebelumnya
    - Hasil: Ensemble 100 pohon yang bekerja bersama untuk prediksi akurat
    
    **Langkah 5: Prediksi Cuaca**
    - Input fitur baru (suhu, kelembaban, dll.) di-scaling dengan parameter training
    - Diproses melalui 100 pohon keputusan secara berurutan
    - Setiap pohon memberikan "suara" prediksi, voting dilakukan dengan weighted average
    - Output: Probabilitas untuk setiap kelas cuaca (Rainy, Sunny, Cloudy, Snowy)
    - Final: Pilih kelas dengan probabilitas tertinggi sebagai prediksi akhir
    
    **Langkah 6: Evaluasi & Validasi**
    - Ukuran performa: Accuracy, Precision, Recall, F1-Score
    - Confusion Matrix menunjukkan akurasi per jenis cuaca
    - Feature Importance mengungkap fitur mana yang paling berpengaruh
    - Hasil: Model mencapai ~95%+ akurasi dalam testing dataset
    
    ---
    
    ### üìà Fitur Paling Berpengaruh (dari Analisis):
    
    1. **Temperature** - Fitur paling penting
       - Perbedaan signifikan antar tipe cuaca
       - Cuaca Sunny memiliki rata-rata suhu lebih tinggi
       - Cuaca Snowy memiliki suhu lebih rendah
    
    2. **Humidity** - Fitur kedua terpenting
       - Cuaca Rainy umumnya kelembaban tinggi
       - Cuaca Sunny kelembaban rendah-sedang
    
    3. **Precipitation** - Fitur ketiga terpenting
       - Cuaca Rainy memiliki presipitasi tinggi
       - Cuaca Sunny presipitasi rendah
    
    4. **Cloud Cover & Season** - Fitur pendukung
       - Membantu membedakan nuansa antar kelas
       - Contextual information untuk prediksi lebih akurat
    
    ---
    
    ### üß† Keputusan Model dalam Prediksi:
    
    Ketika menerima input baru, model melakukan:
    1. ‚úì Cek Range Suhu ‚Üí Kategori cuaca utama
    2. ‚úì Validasi Kelembaban ‚Üí Penyesuaian prediksi
    3. ‚úì Analisis Presipitasi ‚Üí Konfirmasi kategori hujan/cerah
    4. ‚úì Pertimbang Cloud Cover & Season ‚Üí Penalaan halus
    5. ‚úì Hitung Probabilitas Akhir ‚Üí Output dengan confidence score
    """)
    
    st.markdown("---")
    
    st.subheader("üìö Penjelasan Algoritma Lainnya")
    
    algorithm_info = {
        "Logistic Regression": {
            "Deskripsi": "Algoritma linear yang menggunakan fungsi sigmoid untuk memprediksi probabilitas kelas.",
            "Kelebihan": ["Cepat", "Interpretable", "Baik untuk data linear"],
            "Kekurangan": ["Kurang baik untuk data non-linear kompleks"]
        },
        "Random Forest": {
            "Deskripsi": "Ensemble learning yang menggabungkan banyak decision trees untuk prediksi robust.",
            "Kelebihan": ["Baik untuk data kompleks", "Resistance terhadap overfitting", "Feature importance"],
            "Kekurangan": ["Lebih lambat", "Hard to interpret"]
        },
        "Gaussian Naive Bayes": {
            "Deskripsi": "Probabilistic classifier berbasis Bayes dengan asumsi fitur independen.",
            "Kelebihan": ["Cepat", "Simple", "Baik untuk small datasets"],
            "Kekurangan": ["Asumsi independensi sering tidak terpenuhi"]
        },
        "SVM": {
            "Deskripsi": "Mencari hyperplane optimal untuk memaksimalkan margin antar kelas.",
            "Kelebihan": ["Baik untuk high-dimensional data", "Versatile dengan kernel trick"],
            "Kekurangan": ["Slow untuk large datasets", "Sulit untuk interpret"]
        }
    }
    
    for algo_name, algo_info in algorithm_info.items():
        with st.expander(f"üìñ {algo_name}"):
            st.write(f"**Deskripsi:** {algo_info['Deskripsi']}")
            st.write("**‚úÖ Kelebihan:**")
            for kelebihan in algo_info['Kelebihan']:
                st.write(f"  - {kelebihan}")
            st.write("**‚ùå Kekurangan:**")
            for kekurangan in algo_info['Kekurangan']:
                st.write(f"  - {kekurangan}")

# ====================== TAB 5: PREDICTION APP ======================
with tab5:
    st.header("üéØ Aplikasi Prediksi")
    
    st.write("Masukkan nilai fitur untuk memprediksi jenis cuaca:")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        temperature = st.slider("Suhu (¬∞C)", -20.0, 50.0, 15.0)
        humidity = st.slider("Kelembaban (%)", 0.0, 150.0, 50.0)
        wind_speed = st.slider("Kecepatan Angin (km/jam)", 0.0, 200.0, 10.0)
    
    with col2:
        precipitation = st.slider("Presipitasi (%)", 0.0, 150.0, 20.0)
        pressure = st.slider("Tekanan Atmosfer (hPa)", 900.0, 1050.0, 1013.0)
        uv_index = st.slider("Indeks UV", 0.0, 11.0, 5.0)
    
    with col3:
        visibility = st.slider("Jarak Pandang (km)", 1.0, 50.0, 10.0)
        
        cloud_cover_option = st.selectbox("Tutupan Awan", ["Clear", "Overcast", "Partly Cloudy"])
        season_option = st.selectbox("Musim", ["Winter", "Spring", "Summer", "Fall"])
        location_option = st.selectbox("Lokasi", ["Urban", "Coastal", "Rural"])
    
    if st.button("üîÆ Prediksi Cuaca", use_container_width=True):
        # Use cached encoders and scalers
        le_cloud = data['le_cloud']
        le_season = data['le_season']
        le_location = data['le_location']
        le_target = data['le_target']
        scaler = data['scaler']
        numerical_cols = data['numerical_cols']
        X_train = data['X_train']
        y_train = data['y_train']
        
        # Train best model (berdasarkan accuracy)
        model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
        model.fit(X_train, y_train)
        
        # Prepare input using cached encoders
        cloud_cover_encoded = le_cloud.transform([cloud_cover_option])[0]
        season_encoded = le_season.transform([season_option])[0]
        location_encoded = le_location.transform([location_option])[0]
        
        input_data = pd.DataFrame({
            'Temperature': [temperature],
            'Humidity': [humidity],
            'Wind Speed': [wind_speed],
            'Precipitation (%)': [precipitation],
            'Cloud Cover': [cloud_cover_encoded],
            'Atmospheric Pressure': [pressure],
            'UV Index': [uv_index],
            'Season': [season_encoded],
            'Visibility (km)': [visibility],
            'Location': [location_encoded]
        })
        
        # Scale input
        input_data[numerical_cols] = scaler.transform(input_data[numerical_cols])
        
        # Predict
        prediction = model.predict(input_data)[0]
        confidence = model.predict_proba(input_data)[0]
        
        weather_types = le_target.classes_
        predicted_weather = weather_types[prediction]
        
        st.markdown("---")
        
        # Display prediction
        weather_emojis = {
            'Rainy': 'üåßÔ∏è',
            'Sunny': '‚òÄÔ∏è',
            'Cloudy': '‚òÅÔ∏è',
            'Snowy': '‚ùÑÔ∏è'
        }
        
        emoji = weather_emojis.get(predicted_weather, 'üå¶Ô∏è')
        
        st.success(f"### {emoji} Prediksi: **{predicted_weather}**")
        
        # Confidence
        st.subheader("üìä Skor Kepercayaan:")
        for i, weather in enumerate(weather_types):
            col1, col2 = st.columns([2, 8])
            with col1:
                st.write(f"**{weather}**")
            with col2:
                st.progress(confidence[i])
                st.write(f"{confidence[i]*100:.2f}%")

# ====================== TAB 6: CONTACT ME ======================
with tab6:
    st.header("üìß Hubungi Saya")
    
    st.markdown("""
    ### üë§ Informasi Kontak
    
    **üìù Nama:** Nurkhaliza  
    **üéì NIM:** B2D023021  
    **üè´ Institusi:** UNIMUS (Universitas Muhammadiyah Semarang)  
    **üìö Program:** Semester 5 - Machine Learning | Sains Data  
    
    ---
    
    ### üí¨ Hubungi Saya Melalui:
    
    **üìß Email:** [lisanurkhaliza99@gmail.com](mailto:lisanurkhaliza99@gmail.com)  
    **üîó GitHub:** [https://github.com/Nurkhaliza](https://github.com/Nurkhaliza)
    
    Silakan hubungi saya untuk diskusi tentang machine learning, data science, atau kolaborasi proyek!
    
    ---
    
    ### üìñ Tentang Proyek
    
    Aplikasi Klasifikasi Cuaca ML ini adalah tugas dari mata kuliah **Machine Learning & Sains Data**.
    
    **Tujuan Proyek:**
    - ‚úÖ Membandingkan performa 5 algoritma ML untuk klasifikasi cuaca
    - ‚úÖ Mengimplementasikan data preprocessing dan feature engineering
    - ‚úÖ Melakukan evaluasi model dengan berbagai metrik (Accuracy, Precision, Recall, F1-Score)
    - ‚úÖ Membuat interface interaktif dengan Streamlit untuk prediksi real-time
    - ‚úÖ Analisis mendalam tentang feature importance dan cara kerja model
    
    **Dataset:**
    - 1000 sampel data cuaca dengan 11 fitur
    - 4 kategori cuaca: Rainy, Sunny, Cloudy, Snowy
    - Data lengkap dengan preprocessing dan normalisasi
    
    **Repository GitHub:**
    [weather-classification-ml](https://github.com/Nurkhaliza/weather-classification-ml)
    
    ---
    
    ### üõ†Ô∏è Teknologi yang Digunakan
    
    - **Framework Web:** Streamlit 1.28.1
    - **ML Libraries:** scikit-learn (5 algoritma: LogisticRegression, RandomForest, GaussianNB, SVM, GradientBoosting)
    - **Data Processing:** pandas, numpy
    - **Visualization:** matplotlib, seaborn
    - **Version Control:** Git & GitHub
    - **Language:** Python 3.x
    
    ---
    
    ### ‚≠ê Fitur Aplikasi
    
    1. **üìä Dataset Analysis** - Eksplorasi data dengan visualisasi lengkap
    2. **üìà Dashboard** - EDA interaktif dengan distribusi fitur
    3. **ü§ñ Machine Learning** - Pipeline ML komprehensif dengan 9 bagian analisis
    4. **üèÜ Best Model** - Penjelasan detail cara kerja model terbaik (Gradient Boosting)
    5. **üéØ Prediction App** - Aplikasi prediksi cuaca real-time interaktif
    6. **üìß Contact** - Informasi kontak dan repository
    
    ---
    
    ### üéì Pembelajaran dari Proyek
    
    Proyek ini mengajarkan:
    - Implementasi machine learning end-to-end
    - Data preprocessing dan feature normalization
    - Model comparison dan evaluation
    - Feature importance analysis
    - Web application development dengan Python
    - Git version control dan GitHub collaboration
    
    ---
    
    ### üôè Terima Kasih!
    
    Semoga aplikasi ini bermanfaat untuk pembelajaran Machine Learning dan Sains Data!
    
    Jika Anda memiliki pertanyaan, saran, atau ingin berkolaborasi, jangan ragu untuk menghubungi saya melalui email atau GitHub. üòä
    """)

